#+title: Programming/Development Notes
#+author: Craig Astill
#+OPTIONS: toc:2
* Arch:
** Package Management:
*** [[https://forum.manjaro.org/t/how-do-i-limit-pamac-or-yays-cpu-core-usage-while-compiling/55043][How do I limit Pamac or yay's CPU core usage while compiling?]]
- Edit ~/etc/makepkg.conf~.
- Modify: ~MAKEFLAGS="-j$(($(nproc)+1))"~ to another value.
  - eg. ~MAKEFLAGS="-j$(($(nproc)-2))"~, to leave 2 cores free.
* Bash:
- ~ps -aef --forest~ for tree view of processes.
** surf | suckless.org software that sucks less
[2022-09-11 Sun 15:49]
https://surf.suckless.org/

surf is a simple web browser based on WebKit2/GTK+. It is able to display websites and follow links. It supports the XEmbed protocol which makes it possible to embed it in another application. Furthermore, one can point surf to another URI by setting its XProperties.
* BuildTools:
- [[https://www.gnu.org/software/make/][GNU Make: Makefiles with build targets]].
- [[https://taskfile.dev/#/][Task: task runner / build tool that aims to be simpler than GNU Make]].
* CI/CD:
** Gitlab:
- [[https://docs.gitlab.com/ee/user/project/quick_actions.html][Gitlab Docs: Quick Actions]] - slash commands in Gitlab.
- [[https://docs.gitlab.com/ee/user/markdown.html#gitlab-specific-references][Gitlab Docs: Special markdown syntax]] - Markdown syntax to do actions from
  commit/comments in Gitlab.
- [[https://docs.gitlab.com/ee/administration/integration/plantuml.html][Gitlab Docs: PlantUML integration]] - Configure a docker container to generate
  in-line PlantUML code blocks into images when rendering Markdown/Restructred
  Text.
- [[https://gitlab.com/gitlab-org/gitlab/-/tree/master/.gitlab/merge_request_templates][Gitlab: ~.gitlab/merge_request_templates/~]] - Gitlab's current [[https://docs.gitlab.com/ee/user/project/description_templates.html][Gitlab Docs: MR
  templates]].
- https://docs.gitlab.com/ee/user/project/releases/release_cicd_examples.html
  - Release stage for an Agent to explicitly tag the repo and handle generating
    tagged artifacts in a release job.
    - https://docs.gitlab.com/ee/ci/yaml/#release.
  - This is different to using a tag trigger and having a job that does work
    when a tag has been pushed.
    - https://docs.gitlab.com/ee/ci/yaml/#rules.
** Gitlab Articles:
- https://about.gitlab.com/blog/2022/09/06/speed-up-your-monorepo-workflow-in-git/
- https://about.gitlab.com/blog/2022/08/31/the-changing-roles-in-devsecops/ - Why and How DevOps roles are changing.
- https://about.gitlab.com/blog/2022/08/30/the-ultimate-guide-to-software-supply-chain-security/
- https://about.gitlab.com/blog/2022/08/30/top-reasons-for-software-release-delays/
- https://about.gitlab.com/blog/2022/07/21/quickly-onboarding-engineers-successfully/
- https://about.gitlab.com/blog/2022/06/29/a-story-of-runner-scaling/
- https://about.gitlab.com/blog/2022/02/16/a-community-driven-advisory-database/
- https://about.gitlab.com/blog/2022/01/20/securing-the-container-host-with-falco/
- https://about.gitlab.com/blog/2021/11/15/top-five-actions-owasp-2021/
- https://about.gitlab.com/blog/2021/11/11/situational-leadership-strategy/
- https://about.gitlab.com/blog/2021/10/11/how-ten-steps-over-ten-years-led-to-the-devops-platform/
- https://about.gitlab.com/blog/2022/08/10/securing-the-software-supply-chain-through-automated-attestation/
- https://about.gitlab.com/blog/2022/08/15/the-importance-of-compliance-in-devops/
- https://about.gitlab.com/blog/2022/08/16/eight-steps-to-prepare-your-team-for-a-devops-platform-migration/
- https://about.gitlab.com/blog/2022/08/17/why-devops-and-zero-trust-go-together/
- https://about.gitlab.com/blog/2022/08/18/the-gitlab-guide-to-modern-software-testing/
- https://about.gitlab.com/blog/2022/08/23/gitlabs-2022-global-devsecops-survey-security-is-the-top-concern-investment/
** Releases:
- https://github.com/changesets/changesets - A tool to manage versioning and changelogs
with a focus on multi-package repositories .
* Databases:
** CAP Theorem:
You can only achieve 2 of these 3 properties of databases:

- *Consistency:* All Clients see the same data at the same time, regardless of
  Node connected to.
- *Availability:* Respond to Client Requests, even during partial Node failure.
- *Partition Tolerance:* System can tolerate network partitions (breaks)
  between some Nodes.
*** Distributed Database:
Typically will have a CP or AP database cluster since CA is not possible in a
distributed scenario due to needing to handle network partitions! ie. *There
will always be partitions, so the choices is Consistency vs Availability!*

- *Consistency (CP):* requires block further writes to all other nodes until data is
  written across them all. Need to return warnings during this
  period. eg. Banking.
- *Availability (AP):*
  - Reads: Keep accepting, but may return stale data.
  - Writes: Keep accepting writes, sync once network partition is resolved.
** Postgres:
- [[https://postgrest.org/en/stable/][PostgREST: Serve a RESTful API from any Postgres database]].
* Dev Environment Setup:
** Factory Reset / Erase / Format / Wipe:
*** Mac:
- Reboot and hold ~Command + r~ until you see the Apple logo and/or hear a
  chime.
  - On an M1 mac, you need to hold the power button down until the ~Start up
    Options~ appears.
- A macOS Utilities window should pop up.
- Select: ~Disk Utility > Drive > Erase~.
**** Secure erase an SSD:
Need to get to the ~Secure Erase Options~ to do full disk erasing.
- Pick: ~Mac OS Extended (Journaled, Encrypted)~ and set an easy password.
- After first erase, change to: ~Mac OS Extended (Journaled)~ and then select
  a: ~Secure Erase Options~, to do full disk wipe.
** Mac config:
*** iterm2
- ~Preferences > Profiles > Keys > General > <Left/Right> Option Key = Esc+~ -
  to fix ~Alt~ to be the ~Meta~ key again.
- ~Preferences > Profiles > Keys > Key Mappings~ Added a new mapping: ~Send:
  "#"~, when ~Alt+3~ is pressed. Fixes sending ~#~ when my keyboard is on the
  Mac layer + ~Esc+~ is set above.
- ~Preferences > Profiles > Colors~ - Tweak the Blue to be brighter to make it
  readable.
- ~Preferences > Profiles > Terminal > Infinite Scrollback~.
*** System
- changed mouse scrolling direction to be normal.
- ~scaled~ + ~smallest~ font = native display resolution.
- Up display timeout time in Power menu.
- Finder: [[https://discussions.apple.com/thread/251374769][How to show hidden files in finder?]] ~Command+Shift+.~ in a Finder
  window.
- ~Preferences > Sharing > AirPlayReceiver~ Disabled due to port conflict
  on 5000.
*** Brew
- ~brew leaves~ list packages without dependencies.
**** emacs:
- [[https://github.com/d12frosted/homebrew-emacs-plus][Github: d12frosted/homebrew-emacs-plus]]
- mu.
- aspell.
- cmake.
- cmake-docs
- ~markdown~ (markdown-preview).
**** Dev:
- [[https://postgrest.org/en/stable/][postgrest]] (~brew services stop postgres~ to avoid conflict with an eigen
  container).
- git-lfs (had to pin, see wiki).
- ~helm~.
- ~lens~ (GUI Kubernetes).
- ~awscli~
- ~xquartz~ for X11 server.
- ~wget~
- ~swig~.
- ~miniforge~ (M1 macs need this instead of miniconda to work).
- ~poetry~.
- ~docker --cask~ to pull down the Docker Desktop (https://formulae.brew.sh/cask/docker).
- ~dive~ (inspect size of docker layers).
- ~yq~ (YAML/XML/TOML CLI
  processor)(https://github.com/kislyuk/yq)(https://github.com/wagoodman/dive/issues/300
  ~yq -r .services[].image docker-compose.yml | xargs -n 1 dive --ci~
- ~hadolint~ - lint dockerfiles (https://github.com/hadolint/hadolint))
**** Experiments:
- ~rust~, ~rustup~.
**** laptop:
- iterm2
- rectangle (snap to area shortcuts).
- [[https://github.com/Dimentium/homebrew-autoraise][Github: Dimentium/homebrew-autoraise]] - focus follows mouse.
- [[https://github.com/ankitpokhrel/jira-cli][Github: ankitpokhrel/jira-cli]].
*** FireFox
- ~about:config~ ~browser.tabs.tabMinWidth = 0~ to disable tab scrolling.
*** Docker
**** Best-Practices
- https://pythonspeed.com/articles/poetry-vs-docker-caching/
**** Run AMD64 containers on ADM64:
- https://erica.works/docker-on-mac-m1/
- https://forums.macrumors.com/threads/docker-on-m1-max-horrible-performance.2321545/
- https://stackoverflow.com/questions/70649002/running-docker-amd64-images-on-arm64-architecture-apple-m1-without-rebuilding
- https://enjoi.dev/posts/2021-07-23-docker-using-amd64-images-on-apple-m1/
- https://www.reddit.com/r/docker/comments/o7u8uy/run_linuxamd64_images_on_m1_mac/
- https://medium.com/homullus/beating-some-performance-into-docker-for-mac-f5d1e732032c
-
**** Building AMD64 containers on ARM64:
- https://docs.docker.com/desktop/multi-arch/
- https://hublog.hubmed.org/archives/002027
- [[https://github.com/docker/for-mac/issues/5364][Github: docker/for-mac: "platform" option in docker-compose.yml ignored (preview version) #5364]]
- https://tongfamily.com/2021/12/15/the-weirdness-that-is-amd64-on-apple-m1-silicon/
- http://www.randallkent.com/2021/12/31/how-to-build-an-amd64-and-arm64-docker-image-on-a-m1-mac/
- https://docs.docker.com/buildx/working-with-buildx/
-
**** Podman (Docker alternative)
- https://medium.com/team-rockstars-it/how-to-implement-a-docker-desktop-alternative-in-macos-with-podman-bbf728d033da
- https://stackoverflow.com/questions/70892894/run-docker-compose-with-podman-as-a-backend-on-macos
- [[https://github.com/containers/podman/issues/13456][Github: containers/podman -  MacOS helper daemon (podman-mac-helper) fails to start and "mount" /var/run/docker.sock #13456]]
- https://devopscube.com/podman-tutorial-beginners/
-
**** Tooling
- [[https://github.com/emacs-lsp/dap-mode/issues/406][Github emacs-lsp/dap-mode: Feature request: support docker #406]]
** Raspberry Pi:
*** [[https://forum.manjaro.org/t/guide-install-manjaro-arm-minimal-headless-on-rpi4-with-wifi/96515][Manjaro headless install directly to a MicroSD card]]:
- Download minimal ARM iso from: https://manjaro.org/download/.
- Unpack compressed image.
- Burn to MicroSD card with: ~sudo dd if=~/Downloads/Manjaro-ARM-minimal*.img of=/dev/mmcblk0 bs=1M status=progress && sync~
- Mount ~ROOT_MNJRO~
  - Click in Thunar, which auto-mounts to: ~/var/run/media/root/~.
  - Or: ~sudo mount -o rw /dev/mmcblk0p2 /mnt~.
- Add WiFi config:
  #+BEGIN_SRC bash
    sudo mkdir -p /mnt/var/lib/iwd
    sudo touch /mnt/var/lib/iwd/<ssid>.psk
    echo "[Security]" >> /mnt/var/lib/<ssid>.psk
    echo "Passphrase=<password>" >> /mnt/var/lib/<ssid>.psk
  #+END_SRC
- Unmount and plug into the Pi and boot.
- ~ssh root@<ip>~
- You'll connect into the CLI Wizard.
*** Kiosk mode:
- *TODO:* Fill out with other details (retroactively looking at an existing
  Pi3B+ with a [[https://shop.pimoroni.com/products/hyperpixel-4?variant=12569539706963][Pimoroni: HyperPixel 4.0 (non-touch) display).]]
- Autostart Chromium by editing:
  ~/rootfs/home/pi/.config/lxsession/LXDE-pi/autostart~ with:
  #+BEGIN_EXAMPLE shell
    @xset s off
    @xset -dpms
    @xset s noblank
    @chromium-browser --kiosk http://<ip/fqdn> --start-fullscreen --incognito
  #+END_EXAMPLE
* Docker:
- [[https://www.youtube.com/watch?v=fqMOX6JJhGo][YouTube: Docker Tutorial for Beginners - A Full DevOps Course on How to Run
  Applications in Containers]].
** Best Practices:
*** No Root Access:
A container should never be run with root-level access. A role-based access
control system will reduce the possibility of accidental access to other
processes running in the same namespace. Either:

- Create a non-root user in the container:
  #+BEGIN_EXAMPLE dockerfile
    FROM python:3.5
    RUN groupadd -r myuser && useradd -r -g myuser myuser
    <HERE DO WHAT YOU HAVE TO DO AS A ROOT USER LIKE INSTALLING PACKAGES ETC.>
    USER myuser
  #+END_EXAMPLE
- Or while running a container from the image use, ~docker run -u 4000
  python:3.5~. This will run the container as a non-root user.
*** Trusted Image Source:
- Docker 1.8 feature that is disabled by default.
- ~export DOCKER_CONTENT_TRUST=1~ to enable.
- Verifies the integrity, authenticity, and publication date of all Docker
  images from the Docker Hub registry, by preventing access to unsigned images.
** Clean-up:
- Removing containers, volumes and dangling images:

  #+BEGIN_EXAMPLE shell
  docker container prune -f
  docker volume prune -f
  docker image prune -f
  #+END_EXAMPLE
- Remove unused images: ~docker image prune --all~.
** ~docker-compose~:
- ~docker-compose up --build~ to force a rebuild (and ignore any previous
  built images).
- ~docker-compose down~ stops (~docker-compose stop~) all running containers in
  the docker compose file and then cleans up containers/networks/images.
** Docker Swarm:
Orchestrator (similar to Kubernetes) but built by the Docker Team.
*** Visualize Docker Swarm Containers across Nodes:
- [[https://github.com/dockersamples/docker-swarm-visualizer][Github: dockersamples/docker-swarm-visualizer]] - Constrain to the Master node
  to visualise the containers across all nodes from the Web Browser.

  Vlisualizer deployed via ~docker run~:
  #+BEGIN_EXAMPLE shell
    docker run -it -d -p 8080:8080 -v /var/run/docker.sock:/var/run/docker.sock dockersamples/visualizer
  #+END_EXAMPLE

  Visualizer deployed via Docker Swarms ~docker service~:
  #+BEGIN_EXAMPLE shell
    docker service create --name=viz --publish=8080:8080/tcp --constraint=node.role==manager --mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock dockersamples/visualizer
  #+END_EXAMPLE
** Networks:
- Can use container name to connect between containers.
- ~docker run -d --name=app1 --link db:db my-app1~ The `--link` command writes
  the provided Container Name (+IP) into: ~/etc/hosts~, so that all references
  to the linked Container work.
*** ~bridge~:
- The default network that all docker containers (without network config) are
  created in.
- Assigns private IP's to each container (eg. ~172.17.0.x~).
- Requires explicit create command to create additional bridge networks.
- DNS defaults to: ~127.0.0.11~.
- Port Mapping to expose Container Ports to the Host.
  - Can run multiple Containers with the same internal port.
*** ~none~:
- Network with no external access.
*** ~Host~:
- Directly map Containers onto the Hosts IP + Port range.
- No ~port~ config required for mapping.
- Cannot support multiple Containers re-using the same Port, due to Host-side
  conflicts.
** Performance:
- Uses ~cgroups~ (Control Groups) to allocate Hosts CPU/Memory to containers.
- Use ~--cpu/--memory~~ to constrain the running container.
** Reduce image size:
- If using ~COPY~ to pull in directories. Add a ~.dockeringnore~ file to add
  exclusions. eg. ~.git~, ~**/tests~, ~**/*.ts~.
- Generate/install in the image at build time instead of ~COPY~ = Docker layer
  caching.
- Check for ~-slim~/~alpine~ versions of the base image.
- Move ~COPY~ commands near end of the file. Avoid Cache misses!
- Pull in versioned OS-packages. Avoid Cache misses, but more Platform burden!
- Use multi-stage docker files to build code in a fat stage, but copy in the
  artifacts in to the thin stage with an ~ENTRYPOINT~

  #+BEGIN_EXAMPLE dockerfile
    FROM microsoft/dotnet:2.2-sdk AS builder
    # 1730MB Fat Stage.
    WORKDIR /app

    COPY *.csproj  .
    RUN dotnet restore

    COPY . .
    RUN dotnet publish --output /out/ --configuration Release

    FROM microsoft/dotnet:2.2-aspnetcore-runtime-alpine
    # 161MB Thin stage.
    WORKDIR /app
    COPY --from=builder /out .
    EXPOSE 80
    ENTRYPOINT ["dotnet", "aspnet-core.dll"]
  #+END_EXAMPLE
* Emacs:
** org-mode:
- ~org-eww-copy-for-org-mode~ to copy text + links from Eww to Org. ~C-y~ to
  paste.
*** Build Your Website with Org Mode - System Crafters
[2022-11-05 Sat 08:50]
https://systemcrafters.net/publishing-websites-with-org-mode/building-the-site/
*** Formatting:
- [[https://orgmode.org/manual/Emphasis-and-Monospace.html][Emphasis and Monospace]]
- *bold*
- /italic/
- _underlined_
- =verbatim=
- ~code~
- +strike-through+
- src_python{inline python}  # ~src_<lang>[<header_arguments>]{<code>}~ [[https://orgmode.org/manual/Structure-of-Code-Blocks.html#Structure-of-Code-Blocks][Structure of Code Blocks]]
- code blocks
#+NAME: <name>
#+BEGIN_SRC <language> <switches> <header arguments>
  <body>
#+END_SRC
- quote blocks
  #+BEGIN_QUOTE
  <body>
  #+END_QUOTE
*** PlantUML + Org Babel:
- https://orgmode.org/worg/org-contrib/babel/languages/ob-doc-plantuml.html
- plantuml block
  #+begin_src plantuml :file designs/hello-uml.png
  Bob -> Alice : Hello World!
  #+end_src
** DAP:
*** Registering a debug template for: ~dap-mode~, to use.
#+BEGIN_EXAMPLE emacs-lisp
(dap-register-debug-template
  "Python :: Run pytest (projectX buffer)"
  (list :type "python"
        :args ""
        :cwd "/Users/<user>/projects/projectX/"
        :program nil
        :module "pytest"
        :arguments "-p no:warnings"
        :request "launch"
        :name "Python :: Run pytest (projectX buffer)"))
#+END_EXAMPLE
** Jupyter:
- https://discourse.julialang.org/t/jupyter-integration-with-emacs/21496/5 -
  basic ~IJulia~ + ~jupyter~ install steps (no use-package).
* Git:
- https://www.conventionalcommits.org/en/v1.0.0/ - A specification for adding
  human and machine readable meaning to commit messages.
- https://github.com/conventional-changelog/conventional-changelog - Generate
  changelogs and release notes from a project's commit messages and metadata.
- https://github.com/conventional-changelog/releaser-tools - Create a
  GitHub/GitLab/etc. release using a project's commit messages and metadata.
* Job hunting:
- https://github.com/readme/guides/technical-interviews
- https://www.codinginterview.com/
- https://www.pramp.com/#/
- https://hackingthesystemsdesigninterview.com
- https://blog.bytebytego.com - Newsletter by Alex Xu (Author of: /"System Design Interview/").
- https://www.siliconmilkroundabout.com - London-based Job Fair.
* Kubernetes:
- [[https://kurl.sh/][kURL: Open Source Kubernetes Installer]].
- https://docs.k3s.io - Lightweight Kubernetes. Easy to install, half the
  memory, all in a binary of less than 100 MB.
- https://www.cncf.io/kubecon-cloudnativecon-events/
** Helm Charts:
- Hierarchical to call sub-charts as sub-dependencies.
- Values to be passed into the charts.
*** [[https://eigentech.slack.com/archives/CH1CHKYP8/p1650553648237999][how does one deploy from a local helm chart without publishing it?]]
- ~helm upgrade --install <deployment_name> <local_chart_dir>~
*** Dagster docs + dump current helm chart values: https://docs.dagster.io/deployment/guides/kubernetes/deploying-with-helm
*** [[https://helm.sh/docs/chart_template_guide/debugging/][Debugging Templates]]:
- ~helm lint~ is your go-to tool for verifying that your chart follows best
  practices.
- ~helm install --dry-run --debug~ or ~helm template --debug~: We've seen this
  trick already. It's a great way to have the server render your templates,
  then return the resulting manifest file.
- ~helm get manifest~: This is a good way to see what templates are installed
  on the server.
- **NOTE:** variable substitution still happens on commented out code in
  templates, so comment out broken sections if it fails to render with ~helm
  install --dry-run --debug~.
- YAML node typing eg. ~age: !!str 21~, or: ~port: !!int "80"~.
**** TODO Document Debugging Workflow                              :WORKFLOW:
- Are there docs already on Confluence on debugging.
- Raise Task to add vscode/emacs debug tasks to ~eigen~.
- Document the workflow with the debugger (include vscode/emacs tutorial links).
- How to debug into a Docker container? - new DockerFile section with ~debugpy~ ??
*** [[https://stackoverflow.com/questions/72126048/error-exec-plugin-invalid-apiversion-client-authentication-k8s-io-v1alpha1-c][SO: invalid apiVersion "client.authentication.k8s.io/v1alpha1"]]
- ~aws eks update-kubeconfig --name ${EKS_CLUSTER_NAME} --region ${REGION}~.
*** [[https://github.com/bitnami/charts/issues/10539][Github/bitnami: Helm charts repository ~index.yaml~ retention policy #10539]] - Drama!!
** Kubernetes Networks:
*** Ingress:
- [[https://www.youtube.com/watch?v=GhZi4DxaxxE][YouTube: Kubernetes Ingress Explained Completely for Beginners]].
- Ingress is the LoadBalancer/Routing defined within the Kubernetes Cluster
  config.
- Still require an external, to the Cluster, Load Balancer (or Proxy) but this
  will just have to deal with a single root URL that is passed into your
  Cluster's Ingress (and then routed to the correct Service's Pod(s)).
- Equivalent to a reverse-proxy like: nginx, HaProxy, Traefik.
**** Ingress Controller:
- Commonly use nginx (or others) as an Ingress Controller
  (eg. ~nginx-ingress-controller~ image).
- Deployment/Service/ConfigMap/Auth Yaml's.
**** Ingress Resource:
- Handles routing to respective service based off the requested URL.
- Can handle 1 or multiple Domain Paths, by creating a ~rule~ for each ~path~.
- ~kubectl describe ingress <image>~
** Local Development:
- https://necessaryeval.com/2021/09/01/kubernetes-primer/ - Local development
  with ~minikube~.
- https://kubernetes.io/blog/2018/05/01/developing-on-kubernetes/
  - Local vs. remote development.
  - Tools:
    - https://github.com/Azure/draft - aims to help you get started deploying
      any app to Kubernetes. It is capable of applying heuristics as to what
      programming language your app is written in and generates a Dockerfile
      along with a Helm chart. It then runs the build for you and deploys
      resulting image to the target cluster via the Helm chart. It also allows
      user to setup port forwarding to localhost very easily.
    - https://github.com/GoogleCloudPlatform/skaffold - tool that aims to
      provide portability for CI integrations with different build system,
      image registry and deployment tools.
    - https://github.com/solo-io/squash - consists of a debug server that is
      fully integrated with Kubernetes, and a IDE plugin.
    - https://www.telepresence.io/ - connects containers running on developer’s
      workstation with a remote Kubernetes cluster using a two-way proxy and
      emulates in-cluster environment as well as provides access to config maps
      and secrets.
    - https://github.com/vapor-ware/ksync - Synchronizes application code (and
      configuration) between your local machine and the container running in
      Kubernetes.
- https://kubernetes.io/docs/tasks/debug/debug-cluster/local-debugging/ -
  Developing and debugging services locally using telepresence.
- http://next.nemethgergely.com/blog/using-kubernetes-for-local-development -
  Local development via ~minikube~ & ~skaffold~.
** [[https://docs.replicated.com/][Replicated]]:
- https://docs.replicated.com/ - Replicated allows software vendors to package
  and securely distribute their application to diverse customer environments,
  including both on-premises and cloud environments.
- https://kubernetes.io/docs/tasks/run-application/run-replicated-stateful-application/
* ML:
** ML Articles:
- https://simonwillison.net/2022/Jul/9/gpt-3-explain-code/
** DagFlow
- [[https://docs.dagster.io/deployment/guides/kubernetes/deploying-with-helm][Dagster: deploying with Helm]].
* Networks:
** DNS:
- https://root-servers.org/ - Root DNS servers at the top of the DNS
  hierarchy. These root servers farm out requests down to Top-Level
  (io/com/net/edu/...) servers who farm out to down to Secondary-Level
  (amazon.com/github.com/...) DNS servers to complete Name-IP lookups.
- *Local Resolver Library:* Local DNS Cache.
- *Local DNS Server:* Hosted by ISP's as a DNS Cache + inspect
  traffic/requests.
* Python:
** Python Articles:
- https://pythonspeed.com/
- https://about.gitlab.com/blog/2022/09/06/test-your-software-supply-chain-security-know-how/
- https://pythoninsider.blogspot.com/2022/09/python-releases-3107-3914-3814-and-3714.html -
  Python releases 3.10.7, 3.9.14, 3.8.14, and 3.7.14 are now available + CVE fix.
** Build Tools:
- https://github.com/benfogle/crossenv - Virtual Environments for
  Cross-Compiling Python Extension Modules.
** CLI packages:
- https://github.com/pallets/click - Command Line Interface Creation Kit
- https://cloup.readthedocs.io/en/stable/ - Click + Option Groups.
- https://github.com/astanin/python-tabulate - Pretty-print tabular data.
- https://github.com/termcolor/termcolor - Abstract out setting text colours.
** Debugging:
- https://github.com/ztlevi/LSP-Debug/blob/master/README.md#L4-L9 - debug
  python via DAP - editor support.
- https://github.com/bloomberg/memray - Python memory profiler.
- https://github.com/benfred/py-spy - Python sampling profiler.
** Django:
- [[https://books.agiliq.com/projects/django-admin-cookbook/en/latest/index.html][Django Admin Cookbook]].
- [[https://django-extensions.readthedocs.io/en/latest/graph_models.html][django-extensions: Graph Models]].
** Celery:
*** Debugging:
**** Celery's remote debugger:
  #+BEGIN_EXAMPLE python
  from celery.contrib import rdb
  ...
  rdb.set_trace()
  #+END_EXAMPLE
- Then connect over telnet: ~telnet localhost 6900~.
- If in docker:
  - add: ~CELERY_RDB_HOST=0.0.0.0~ to ~.env~.
  - Expose Celery debug port in ~docker.compose.yml~. eg. ~6901~
  - ~telnet localhost 6901~ from host.
**** Debug Celery via PDB in Django:
- Add ~CELERY_TASK_ALWAYS_EAGER=True~ in: ~settings.py~.
** Conda:
- https://conda-forge.org/blog/posts/2020-10-29-macos-arm64/ - macOS ARM builds
  on conda-forge.
- [[https://github.com/conda/conda/issues/9957][conda/conda - conda update breaks conda with ImportError: libffi.so.6: cannot open shared object file #9957]]
*** Conda + Emacs:
- [[https://github.com/necaris/conda.el/issues/39][necaris/conda.el - Cannot activate any env on OSX #39]]
*** Conda + Docker:
- https://uwekorn.com/2021/03/01/deploying-conda-environments-in-docker-how-to-do-it-right.html
*** Mamba instead of Conda:
- https://mamba.readthedocs.io/en/latest/user_guide/mamba.html
- https://labs.epi2me.io/conda-or-mamba-for-production/
** poetry:
- [[https://python-poetry.org/docs/managing-environments/#switching-between-environments][Set poetry python version]]: ~poetry env use python<x.y>~.
- ~poetry show --tree~ for poetry dependency graph.
*** https://github.com/opeco17/poetry-audit-plugin                     :READ:
*** [[https://github.com/python-poetry/poetry/issues/2094#issuecomment-1243195601][python-poetry/poetry: Poetry is extremely slow when resolving the dependencies (#2094)]]:
@Kache, It appears to search through dependencies depth-first, rather than breadth-first. As a result, you've probably got a something earlier in your pyproject.toml that depends on ddtrace, so the dependency resolver grabbed that version and tried to resolve using that, rather than the ddtrace version you've specified.

I've had some success moving the dependencies I want exact version logic prioritizing earlier in the pyproject.toml file.

(I also disabled IPv6, upgraded to poetry 1.2x, and have reduced the possible space for the troubling aws libraries (boto3 and awsci, for me) so those go at the very end of my dependency file and have only a few recent versions to chew through.

I'm seeing dependency resolution time between 5 and 35 seconds most of the time now.
** Security:
- https://github.com/sonatype-nexus-community/jake - report vulnerabilities.
- https://adamj.eu/tech/2019/04/10/how-to-score-a+-for-security-headers-on-your-django-website/
** Templating:
- https://www.makotemplates.org/ - Mako is a template library written in
  Python. It provides a familiar, non-XML syntax which compiles into Python
  modules for maximum performance.
** Testing:
*** [[https://hypothesis.readthedocs.io/en/latest/][hypothesis]]:
Hypothesis is a Python library for creating unit tests which are simpler to
write and more powerful when run, finding edge cases in your code you wouldn’t
have thought to look for. It is stable, powerful and easy to add to any
existing test suite.
- https://hypothesis.works/
- Uses ML to do [[https://en.wikipedia.org/wiki/QuickCheck][/"Property-based testing/".]]
*** pytest:
- [[https://docs.pytest.org/en/6.2.x/warnings.html#disabling-warning-capture-entirely][Disable warnings]] with: ~-p no:warnings~.
** Web Frameworks:
- [[https://www.tornadoweb.org/en/stable/][Tornado]] - Python web framework and asynchronous networking library. Ideal for
  long polling, WebSockets and other long-lived connections.
* React:
- View cookies in browser: ~Developer Tools > Storage Tab > Cookies~.
- ~redux~ is the store of all BE DB state in the FE.
- Add ~&profile~ to an API call to get performance output!!
- ~npm install --target_arch=x64~ - until there is arm support.
- https://github.com/marmelab/react-admin
- Print all object properties: ~console.log(Object.getOwnPropertyNames(obj))~.
** AST (Abstract Syntax Tree):
What is Abstract Syntax Tree?

#+BEGIN_QUOTE
It is a hierarchical program representation that presents source code structure
according to the grammar of a programming language, each AST node corresponds
to an item of a source code.
#+END_QUOTE

- https://itnext.io/ast-for-javascript-developers-3e79aeb08343
* Security:
** Security Bodies/Sites:
- [[https://www.first.org/cvss/][CVSS (Common Vulnerability Scoring System)]] - Used in the scoring of PEN Tests.
- [[https://www.cve.org/][CVE (CyberSecurity Vulnerabilities)]] ([[https://cve.mitre.org/index.html][Old CVE site (Should be dead in
  2023)]]). - collection of all security vulnerabilities.
- [[https://owasp.org/][OWASP (Open Web Application Security Project)]] - Nonprofit looking to improve
  security through Open-Source projects.
- https://infosec.mozilla.org/guidelines/web_security
** Terminology:
*** Vertical Separation Flaw:
- Access resources granted to more privileged accounts.
- eg. gaining Administrator privileges.
*** Horizontal Separation Flaw:
- Access to resources granted to a similarly configured account.
- eg. modifying data belonging to a different User of the same Application.
** Security Articles:
- https://www.cve.org/ -  Identify, define, and catalog publicly disclosed
  cybersecurity vulnerabilities.
- https://cwe.mitre.org/top25/archive/2022/2022_cwe_top25.html
- https://owasp.org/ - The Open Web Application Security Project® (OWASP) is a
  nonprofit foundation that works to improve the security of software.
- https://owasp.org/www-project-top-ten/
- https://signal.org/blog/building-faster-oram/
- https://arstechnica.com/?p=1872326 - 10 malicious Python packages exposed in
  latest repository attack.
- https://www.synopsys.com/blogs/software-security/sast-vs-dast-difference/ -
  Static (White box) vs Dynamic (Black box) Application Security Testing.
** Tools:
- https://www.rapid7.com/products/insightappsec/ - InsightAppSec performs
  black-box security testing to automate identification, triage
  vulnerabilities, prioritize actions, and remediate application risk.
- https://www.rapid7.com/products/insightvm/ - Discover risks across all your
  endpoints, cloud, and virtualized infrastructure.
- https://www.keycloak.org/ - Open Source Identity and Access Management Add
  authentication to applications and secure services with minimum effort.  No
  need to deal with storing users or authenticating users.  Keycloak provides
  user federation, strong authentication, user management, fine-grained
  authorization, and more.
*** WireGuard: fast, modern, secure VPN tunnel
[2022-09-11 Sun 15:47]
https://www.wireguard.com/

WireGuard® is an extremely simple yet fast and modern VPN that utilizes state-of-the-art cryptography. It aims to be faster, simpler, leaner, and more useful than IPsec, while avoiding the massive headache. It intends to be considerably more performant than OpenVPN. WireGuard is designed as a general purpose VPN for running on embedded interfaces and super computers alike, fit for many different circumstances. Initially released for the Linux kernel, it is now cross-platform (Windows, macOS, BSD, iOS, Android) and widely deployable. It is currently under heavy development, but already it might be regarded as the most secure, easiest to use, and simplest VPN solution in the industry.
* System Design:
** Distributed Networking:
*** [[https://www.envoyproxy.io/][Envoy Proxy]] ([[https://www.envoyproxy.io/docs/envoy/latest/][Envoy docs]]):
#+BEGIN_QUOTE
The network should be transparent to applications. When network and application
problems do occur it should be easy to determine the source of the problem.
#+END_QUOTE

As on the ground microservice practitioners quickly realize, the majority of
operational problems that arise when moving to a distributed architecture are
ultimately grounded in two areas: networking and observability. It is simply an
orders of magnitude larger problem to network and debug a set of intertwined
distributed services versus a single monolithic application.

Originally built at Lyft, Envoy is a high performance C++ distributed proxy
designed for single services and applications, as well as a communication bus
and “universal data plane” designed for large microservice “service mesh”
architectures. Built on the learnings of solutions such as NGINX, HAProxy,
hardware load balancers, and cloud load balancers, Envoy runs alongside every
application and abstracts the network by providing common features in a
platform-agnostic manner. When all service traffic in an infrastructure flows
via an Envoy mesh, it becomes easy to visualize problem areas via consistent
observability, tune overall performance, and add substrate features in a single
place.

- Out of Process Architecture - Self-contained, low memory footprint server
  that runs alongside Application.
- HTTP/2, (HTTP/3 in alpha ~1.19.0~) gRPC support.
  - Transparent HTTP/1.1 / HTTP/2 proxy.
- Load Balancing - retries, circuit breaking, global rate limiting, request
  shadowing, zone local load balancing, etc.
- Configuration management API's.
- Service Discovery - eg. via DNS resolution.
- Front/Edge Proxy Support.
- Observability - L7 traffic, distributed tracing, wire-level observations of
  MongoDB, DynamoDB, Redis, Postgres.
- Health Checking - Assume Eventual Consistency.
- YAML config files.

See: [[https://www.envoyproxy.io/docs/envoy/latest/intro/life_of_a_request][Envoy (Docs): Life of a Request]].
** Queues:
*** Glossary:
**** Message Broker:
- Direct communication between explicit Services (one-to-one).
- Responsibilities: Validate, Route, Store, Deliver messages to designated
  recipient.
- Intermediary between Services/Applications.
  - ie. *Decouple knowledge of Receivers/Consumers location from Sender*.
  - May have: 0, 1, Many Consumers (unknown to Sender).
**** Publish/Subscribe:
- Message distribution pattern.
- Broadcast-style distribution (one-to-many).
*** [[http://kafka.apache.org/][Kafka]]:
Apache Kafka is an open-source distributed event *streaming* platform used by
thousands of companies for high-performance data pipelines, streaming
analytics, data integration, and mission-critical applications.
- 2011.
- Java/Scala-based.
  - SDK for adding custom support of other languages.
- Streams.
  - Ideal for *A* to *B* streaming for max throughput and simple routing.
  - Ideal for:
    - Event Sourcing.
    - Stream Processing.
    - Modelling Changes to a System as a Sequence of Events.
    - Processing Data in multi-stage pipelines.
    - Routine System auditing.
    - Storing messages permanently.
  - *Framework for storing, reading, re-reading and analysing streaming data.*
- Throughput.
- Uses Pub/Sub pattern.
- Uses a Message Log, instead of a Message Queue.
  - *Pull-based*
  - Consumer must request to get batches of messages (offsets).
    - PRO: network efficiency.
    - CON: High-latency.
- *Use Data Lake analysis tools to efficiently store, manage, analyse the Kafka
  streams.*
**** Breakdown:
See: [[https://www.simplilearn.com/kafka-vs-rabbitmq-article][SimpliLearn: Kafka VS RabitMQ]].

- *Performance:* 1 million messages per second.
- *Message Retention:* Policy-based.
- *Data Type:* Operational.
- *Consumer Mode:* Dumb Broker / Smart Consumer.
- *Topology:* Pub/Sub.
- *Payload Size:* Default 1MB limit.
- *Usage Cases:* Massive data / High throughput cases.
*** MSSQL [[https://learn.microsoft.com/en-us/sql/database-engine/service-broker/building-applications-with-service-broker?view=sql-server-ver16][Service Broker]]:
Applies to: ￼ SQL Server (all supported versions) ￼ Azure SQL Managed Instance

Any program that can run *Transact-SQL statements* can use Service Broker. A
Service Broker application can be implemented as a program running outside of
SQL Server, or as a stored procedure written in Transact-SQL or a .NET
language.

A program that uses Service Broker is typically composed of a number of
components working together to accomplish a task. A program that initiates a
conversation creates and sends a message to another service. That program may
wait for a response, or exit immediately and rely on another program to process
the response. For a service that is the target of a conversation, the program
receives an incoming message from the queue for the service, reads the message
data, does any necessary processing, and then creates and sends a response
message if appropriate.

Service Broker extends Transact-SQL. An application does not need a special
object model or library to work with Service Broker. Instead, programs send
Transact-SQL commands to SQL Server and process the results of those
commands. An application can be activated by Service Broker, can run as a
background service, can run as a scheduled job, or can be started in response
to an event.
**** Uses:
- [[https://learn.microsoft.com/en-us/sql/database-engine/service-broker/messages?view=sql-server-ver16][Messages]].
- [[https://learn.microsoft.com/en-us/sql/database-engine/service-broker/queues?view=sql-server-ver16][Queues]].
**** Why?:
- Consolidation if already in Windows (MSSQL) Eco-system.
  - Service Broker is a part of the MSSQL deployment.
  - Messages are R/W from the same DB that Application(s) uses.
  - Offload message queuing outside of the Application to the Platform (DB).
*** Python Module Queues:
These are low-level queues that can be used within Python Applications, where
the same module is used on both sides of the queue:

- [[https://docs.python.org/3/library/asyncio-queue.html][~asyncio.queue~]] - Async. Not thread-safe, but designed for ~async~ / ~await~
  code.
- [[https://docs.python.org/3/library/queue.html#module-queue][~queue~ (built-in)]] - Synchronous. Thread-safe. Multi-Producer /
  Multi-Consumer queues.
- [[https://www.tornadoweb.org/en/stable/queues.html?highlight=queue][~tornado.queues~]] - Async. Queues for Tornado coroutines, like:
  [[https://docs.python.org/3/library/asyncio-queue.html][~asyncio.queue~]].
*** [[https://www.rabbitmq.com][RabbitMQ]]:
- Distributed Message Broker
  - Deploy a Cluster of Nodes = HA.
- *Push-based*
  - Consumer prefetch limits.
  - Low-latency messaging.
  - Ideal for:
    - Complex (non-trivial) routing to multiple Consumers/Applications.
    - High-throughput & reliable background jobs.
    - Rapid request-response.
    - Load balance across Worker nodes (20k+ messages/second).
    - Long running tasks.
    - Communication/Integration between and within Applications.
- Implements AMQP natively (and AMQP (future versions), HTTP, STOMP, MQTT via
  plugins).
- Large official support for popular languages + plugins.
**** Breakdown:

See: [[https://www.simplilearn.com/kafka-vs-rabbitmq-article][SimpliLearn: Kafka VS RabitMQ]].

- *Performance:* 4k-10k messages per second.
- *Message Retention:* Acknowledgement-based.
- *Data Type:* Transactional.
- *Consumer Mode:* Smart Broker / Dumb Consumer.
- *Topology:* Exchange Type: Direct, Fan out, Topic, Header-based.
- *Payload Size:* No constraints.
- *Usage Cases:* Simple use cases.
*** [[https://zeromq.org][ZeroMQ]]:
ZeroMQ (also known as ØMQ, 0MQ, or zmq) looks like an embeddable networking
library but acts like a concurrency framework. It gives you sockets that carry
atomic messages across various transports like in-process, inter-process, TCP,
and multicast. You can connect sockets N-to-N with patterns like fan-out,
pub-sub, task distribution, and request-reply. It's fast enough to be the
fabric for clustered products. Its asynchronous I/O model gives you scalable
multicore applications, built as asynchronous message-processing tasks. It has
a score of language APIs and runs on most operating systems.
** Ask Why a System Works?:
- learn how popular applications work at a high-level.
- Start to understand why some component is used instead of another.
- Build serious side projects. Start simple and iterate to improve & refine it.
- Build a system from scratch and get familiar with all the processes and details of its construction.
- Focus less on mechanics and more on trade-offs.
- Focus on the high-level. Low-level will crop up.
** Breakdown strategies:
- Ask refining questions.
  - *Functional:* Requirements the Client needs directly. eg. Send messages in near real-time to contacts.
  - *Non-functional:* indirect requirements. eg. Performance shouldn't degrade with load.
  - Clarify assumptions.
  - Honesty when ignorant.
- Handle the data.
  - Data size now?
  - Data growth rate?
  - How data is consumed by User or othe SubSystems?
  - Read / Write heavy?
  - Strict or Eventual Consistency?
  - what's the durability target of the data?
  - Privacy/Regulatory concerns for storing/transferring User data?
- Discuss the components.
  - Highlight reasoning.
  - Talk around conflicts with examples of pain/components needed to work the other options.
  - High-level API design for User clarity.
- Discuss trade-offs.
  - Pros/Cons.
  - Monetary/Technical complexity (aim for Resource efficiency).
  - Plan for this designs weakness.
  - Highlight and explain weaknesses. eg. Design won't scale, but added monitoring, to reduce cost and time to do a new design.
  - Add fault tolerance and security to the design.
** Abstractions:
- Network: Use RPCs (Remote Procedure Calls) to abstract away network communications and make all calls appear to be local.
-
* Training Sites:
- https://www.educative.io/ - Text-based teaching resources (instead of video)
  and web-based coding environments.`
